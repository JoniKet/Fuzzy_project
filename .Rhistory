extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# plotting the decision tree
prp(classifier, main = (' ACC:' , round(acc,4)),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# plotting the decision tree
prp(classifier, main = 'asd' + acc,
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# plotting the decision tree
prp(classifier, main = {'asd' + acc},
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
{'asd' , acc}
{'asd' + acc}
tostring(acc)
toString(acc)
toString(round(acc,4)
toString(round(acc,4))
round(acc,4)
toString(round(acc,4))
'asd' + toString(round(acc,4))
paste('ACC:',toString(round(acc,4)), sep = " ")
init_cp = 0.003
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.004
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.005
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.006
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.005
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.0055
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.0052
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.0054
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),,
nn = TRUE,
fallen.leaves = TRUE,
shadow.col = "gray")
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE,
shadow.col = "gray")
shadow.col = "gray"
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE,)
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.0052
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.0057
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.0055
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.0054
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.0055
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.006
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.009
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.001
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.01
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.03
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.05
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.04
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.03
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
# Feature Scaling
train[4:10] = scale(train[4:10])
test[4:10] = scale(test[4:10])
# checking differend sizes of trees
# Fitting Random Forest Classification to the Training set
# install.packages('randomForest')
init_cp = 0.03
library(rpart)
library(rpart.plot)
classifier = rpart(formula = y ~ .,
data = train,
method = 'class',
cp = init_cp) # the complexity parameter is used to find optimal tree size
# Predicting the Test set results
y_pred = predict(classifier, newdata = test[-48],type = 'class')
# Making the Confusion Matrix
cm = table(test[, 48], y_pred)
acc = (cm[1,1]+cm[2,2])/(cm[1,1]+cm[2,2]+cm[1,2]+cm[2,1])
sen = cm[2,2]/(cm[2,2]+cm[2,1])
spe = cm[1,1]/(cm[1,1]+cm[1,2])
# plotting the decision tree
prp(classifier, main = paste('Complexity parameter =',toString(init_cp),'ACC:',toString(round(acc,4)), sep = " "),
extra = 106,
fallen.leaves = TRUE)
acc
sen
spe
